
# System 1
The main function of System 1 is to maintain and update a model of your personal world, which represents what is normal in it.

System 1 loves patterns and will seek them out when there is a major event. A major event is supposed to have consequences, and consequences need causes to explain them
- ex. Bond prices rise upon Saddam Hussein capture, or coincidence?
- System 1 loves to invent [[narratives|psychology.narratives]]

"After spending a day exploring beautiful sights of new York, Jane suddenly realized that her wallet was missing"
- In surprise recall tests of this story, the word "pickpocket" was strongly associated with the story, even though it never appeared

System 1 understands sentences by trying to connect the dots and make the story coherent. This resulting cogent story causes us to be gullible and believe too strongly in whatever we believe.
- expl: If you can make a coherent story out of some percentage of the facts and fill in the gaps yourself, you are likely to believe it, because it makes sense. However, it did not necessarily happen this way, it's just a coherent story that is tricking you into thinking like that.
- ex. There is a story about a man who went to visit a professor at his home. Outside the house the dog was playing on the lawn. When the professor open the door to let the man in, the dog ran into the house. Later the professor asked the man, do you always travel with your dog? The man replied, "it’s not my dog. I thought it was yours"
    - this story demonstrates how System 1 is writing a narrative in the background without us even realizing it.

When uncertain, System 1 bets on an answer, and the bets are guided by experience. The rules of the betting are intelligent: recent events and the current context have the most weight in determining an interpretation. When no recent event comes to mind, more distant memories govern. Among your earliest and most memorable experiences was singing your ABCs; you did not sing your A13Cs.

Because System 1 represents categories by a prototype or a set of typical exemplars, it deals well with averages but poorly with sums.

Your emotional attitude to such things as irradiated food, red meat, nuclear power, tattoos, or motorcycles drives your beliefs about their benefits and their risks.

System 1 generates impressions, feelings, and inclinations; when endorsed by System 2 these become beliefs, attitudes, and intentions

System 1 understands sentences by trying to make them true, and the selective activation of compatible thoughts produces a family of systematic errors that make us gullible and prone to believe too strongly whatever we believe.

You surely understand in principle that worthless information should not be treated differently from a complete lack of information, but WYSIATI makes it very difficult to apply that principle. Unless you decide immediately to reject evidence (for example, by determining that you received it from a liar), your System 1 will automatically process the information available as if it were true. 

### System 1 is overconfident
The measure of success for System 1 is the coherence of the story it manages to create. 
- The amount and quality of the data on which the story is based are largely irrelevant. When information is scarce, which is a common occurrence, System 1 operates as a machine for jumping to conclusions.
 
Confidence is a feeling, which reflects the coherence of the information and the cognitive ease of processing it.
- In other words, confidence in a belief can be traced to two related impressions: cognitive ease and coherence
- Put another way, confidence is a function of cognitive ease and coherence

### How System 1 responds to statistics
System 1 (your intuition) has no capacity to understand statistics. This is significant, because in events that require no statistical analysis, system 1 does well at connecting cause and effect (hitting egg with hammer). However, in understanding why rural states have higher incidences of kidney cancer, the mere statistics of having smaller sample sizes doesn't cross the mind of system 1. It looks for logical links and finds something else to explain the phenomenon.

System 1 will pay attention to statistics if it offers a cause and effect type of answer to the question. this is why sometimes statistics will have an effect on answers.
- ex. 85% of the cabs in the city are blue cabs in 15% are Green cabs. I told you that a Green cab rear ended me yesterday but my reliability is only 80%. In another scenario 85% of the blue cabs cause the accidents.

See how your impression of cause and effect changed the story and made it more clear what the cause was? this shows that people do indeed pay attention to base rates but only when it offers a cause-and-effect type of explanation.

This example also illustrates that there are two types of Base rates:
1. statistical base rates - facts about a population to which a case belongs but are not relevant to the individual case. (Generally underweighted and sometimes neglected all together)
2. causal base rates - change your view of how the individual case came to be. Creates a stereotype in your mind. (Treated as information about the individual case)

### Intensity matching
- This is a system 1 strength
    - This is because people have an intuition for averages.
    - ex. his hair is as long as she is tall. 
        - if a girl is 6'2", then we know that is *unordinarily tall* for a woman. This causes us to approximate the length of the man's hair following a similar description, *unordinarily long*   
    - Ex. Match the loudness of music to the brightness of a light
    - Ex. Match the ability of a 4 year old to read fluently to the height of a male (ie. How tall would she be in terms of male height? 6'5"?)
    
System 1 has more influence on behavior when System 2 is busy

some people are more like their System 2; others are closer to their System 1.

# System 2
System 2 works on data that is retrieved from [[memory|memory]] (ie. from system 1). System 2 is therefore susceptible to the biasing influence of [[anchors|self.bias.anchoring]] that make information easier to retrieve.

A happy mood loosens the control of System 2 over performance: when in a good mood, people become more intuitive and more creative but also less vigilant and more prone to logical errors.

### Analogy: System1/System2 as a caching system
You ask yourself a question like "does my dad have integrity?" And you immediately answer "yea", but this is just retrieved from your mental cache. If you do the actual network request maybe you’ll find a different answer
